data <- read.csv("OA 1.1 stat data.txt")
data()
clcl
clc
clear
data <- read.csv("OA 1.1 stat data.txt")
head(data)
install.packages("dplyr")
library(dplyr)
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x, y = weight)) +
geom_point(aes(color = color)) +
labs(title = "Scatter Plot of Weight vs. Marker", x = "Marker", y = "Weight")
library(ggplot2)
install.packages("ggplot2")
ggplot(data, aes(x = color)) +
geom_bar() +
labs(title = "Color Distribution", x = "Color", y = "Count")
library(ggplot2)
# can also read a text file that uses some separation (,) using read.csv
data <- read.csv("OA 1.1 stat data.txt")
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x, y = weight)) +
geom_point(aes(color = color)) +
labs(title = "Scatter Plot of Weight vs. Marker", x = "Marker", y = "Weight")
ggplot(data, aes(x = feed)) +
geom_bar() +
labs(title = "Color Distribution", x = "feed", y = "Count")
ggplot(data, aes(x = feed)) +
geom_bar() +
labs(title = "Color Distribution", x = "feed", y = "Count")
ggplot(data, aes(x = feed)) +
geom_bar() +
labs(title = "Color Distribution", x = "feed", y = "Count")
ggplot(data, aes(x = feed)) +
#  geom_bar() +
#
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x = X, y = weight)) +
geom_point(aes(feed = feed)) +
labs(title = "Scatter Plot of Weight vs. Marker", x = "x", y = "Weight")
rlang::last_trace()
install.packages("crayon")
library(crayon)
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x = X, y = weight)) +
geom_point(aes(feed = feed)) +
labs(title = "Scatter Plot of Weight vs. Marker", x = "x", y = "Weight")
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x = feed, y = weight)) +
geom_point(aes(feed = feed)) +
labs(title = "Scatter Plot of Weight vs. Marker", x = "x", y = "Weight")
# head(data) # shows the first 6 rows in console
ggplot(data, aes(x = feed, y = weight)) +
geom_point(aes(feed = feed)) +
labs(title = "Scatter Plot of Weight vs. Feed", x = "Feed", y = "Weight")
kruskal_result$p.value
kruskal_result$p.value
summary(anova_result)
install.packages("vcd")
library(vcd)
summary(anova_result)
summary(anova_result)
summary(anova_result)
print(posthoc_anova)
print(posthoc_anova)
print(summary(anova_result))
# Load required libraries
library(dplyr)     # For data manipulation
library(ggplot2)   # For data visualization
library(MASS)      # For Cramer's V calculation
library(stats)     # For ANOVA and Kruskal-Wallis tests
# Data Visualization
# Scatter plot of weight vs. feed
ggplot(data, aes(x = weight, y = factor(feed))) +
geom_point(aes(color = feed)) +
labs(x = "Weight", y = "Feed", title = "Scatter Plot of Weight vs. Feed")
# Box plot of weight by feed
ggplot(data, aes(x = factor(feed), y = weight, fill = feed)) +
geom_boxplot() +
labs(x = "Feed", y = "Weight", title = "Box Plot of Weight by Feed") +
theme(legend.position = "none")  # Hide legend for better view
print(paste("Cramer's V:", cramer_v))
# Correlation Analysis
# Categorical-Categorical Correlation (Cramer's V)
contingency_table <- table(data$feed, data$weight)
cramer_v <- assocstats(contingency_table)$cramer
print(paste("Cramer's V:", cramer_v))
# Categorical-Continuous Correlation (ANOVA)
anova_result <- aov(weight ~ feed, data = data)
print(summary(anova_result))
# Post hoc tests (if ANOVA/Kruskal-Wallis is significant)
posthoc_anova <- summary(glht(anova_result, linfct = mcp(feed = "Tukey")))
install.packages("glht")
# Post hoc tests (if ANOVA/Kruskal-Wallis is significant)
posthoc_anova <- summary(glht(anova_result, linfct = mcp(feed = "Tukey")))
# Post hoc tests (if ANOVA is significant)
posthoc_anova <- glht(anova_result, linfct = mcp(feed = "Tukey"))
print(summary(posthoc_anova))
# Post hoc tests (if ANOVA is significant)
posthoc_anova <- glht(anova_result, linfct = mcp(feed = "Tukey"))
# Post hoc tests (if ANOVA is significant)
if (anova_result$`Pr(>F)`[1] < 0.05) {
posthoc_anova <- TukeyHSD(anova_result, "feed")
print(posthoc_anova)
} else {
print("ANOVA not significant, no post hoc tests performed.")
}
# Post hoc tests (if ANOVA is significant)
if (anova_result$`Pr(>F)`[1] < 0.05) {
posthoc_anova <- TukeyHSD(anova_result, "feed")
print(posthoc_anova)
} else {
print("ANOVA not significant, no post hoc tests performed.")
}
# Post hoc tests (if ANOVA is significant)
if (anova_result$`Pr(>F)`[1] < 0.05) {
posthoc_anova <- TukeyHSD(anova_result, "feed")
print(posthoc_anova)
} else {
print("ANOVA not significant, no post hoc tests performed.")
}
# Post hoc tests (if ANOVA is significant)
if (anova_result$`Pr(>F)`[1] < 0.05) {
posthoc_anova <- TukeyHSD(anova_result, "feed")
print(posthoc_anova)
} else {
print("ANOVA not significant, no post hoc tests performed.")
}
# Check if ANOVA is significant and perform post hoc tests
if (anova_result$`Pr(>F)`[1] < 0.05) {
posthoc_anova <- TukeyHSD(aov_result)
print(posthoc_anova)
} else {
print("ANOVA not significant, no post hoc tests performed.")
}
# Categorical-Continuous Correlation (ANOVA)
anova_result <- aov(weight ~ feed, data = data)
print(summary(anova_result))
# Load required libraries
library(dplyr)     # For data manipulation
library(ggplot2)   # For data visualization
library(MASS)      # For Cramer's V calculation
source("C:/Users/brtas/Documents/R files/OA 1.1 (part 2).R", echo=TRUE)
labs(x = "Feed", y = "Weight", title = "Box Plot of Weight by Feed")
anova_result <- aov(chicken_weight ~ feed_type, data = data)
anova_result <- aov(weight ~ feed, data = data)
summary(anova_result)
summary(anova_result)
View(data)
source("C:/Users/brtas/Documents/R files/OA 1.1 (part 2).R", echo=TRUE)
git config --global user.email "brta.shp@gmail.com"
git config --global user.email "brta.shp@gmail.com"
git config --global user.email "brta.shp@gmail.com"
git config --global user.email brta.shp@gmail.com
git config --global user.email "brta.shp@gmail.com"
install.packages("usethis")
usethis::create_github_token()
gitcreds::gitcreds_set()
gitcreds::gitcreds_set()
1
gitcreds::gitcreds_set()
gitcreds::gitcreds_set(Price Pioneers)
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
gitcreds::gitcreds_set()
setwd("C:/Users/brtas/Documents/GitHub/Housing-ML-Project")
# submission 14, 0.13712
# rank is based on RMSE
# trying to normalize the highest correlated values
# load libraries
library(caTools)
library(randomForest)
library(dplyr)
library(ggplot2)
#install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
library(stats)
# loading data
dataTrain = read.csv("train.csv")
dataTest = read.csv("test.csv")
# remove unnecessary columns
dataTrain$Id = NULL
dataTest$Id = NULL
dataTrain$PoolQC = NULL
dataTest$PoolQC = NULL
dataTrain$MiscFeature = NULL
dataTest$MiscFeature = NULL
dataTrain$Alley = NULL
dataTest$Alley = NULL
dataTrain$Fence = NULL
dataTest$Fence = NULL
dataTrain$MSZoning = NULL
dataTest$MSZoning = NULL
#SalePrice = dataTrain$SalePrice
# log transforming SalePrice since it is not normalized
SalePrice1 <- log(dataTrain$SalePrice)
SalePrice <- log(dataTrain$SalePrice)
dataTrain$SalePrice = SalePrice1
# cleaning Train and test
character_columns = sapply(dataTrain, is.character)
dataTrainChar = dataTrain[, character_columns]
character_columns = sapply(dataTrain, is.character)
dataTestChar = dataTest[, character_columns]
#below works for test
for (col_name in names(dataTrainChar)) {
mean_sale_price = tapply(SalePrice, dataTrainChar[[col_name]], mean)
# Use a different variable name for rank
rank_values = rank(mean_sale_price)
# Rename the values in dataTestChar based on rank
dataTestChar[[col_name]] <- ifelse(!is.na(match(dataTestChar[[col_name]], names(mean_sale_price))),
rank_values[match(dataTestChar[[col_name]], names(mean_sale_price))],
dataTestChar[[col_name]])
dataTestChar[[col_name]] = as.numeric(dataTestChar[[col_name]])
}
# below works for train
for (col_name in names(dataTrainChar)) {
# If the column is a factor, calculate the mean SalePrice for each unique value
mean_sale_price = tapply(SalePrice, dataTrainChar[[col_name]], mean)
#ordered = order(mean_sale_price)
rank = rank(mean_sale_price)
# Add the results to the result data frame
dataTrainChar[[col_name]] <- ifelse(!is.na(match(dataTrainChar[[col_name]], names(rank))),
rank[match(dataTrainChar[[col_name]], names(rank))],
dataTrainChar[[col_name]])
dataTrainChar[[col_name]] = as.numeric(dataTrainChar[[col_name]])
}
# creates dataframe with only numeric/int values for train
missing_columns = setdiff(names(dataTrain), names(dataTrainChar))
dataTrainNum <- dataTrain[, missing_columns]
# removes the sale price column
dataTrainNum$SalePrice = NULL
# below for cleaning test data
# creates dataframe with only numeric/int values
missing_columns = setdiff(names(dataTest), names(dataTestChar))
dataTestNum <- dataTest[, missing_columns]
# combines everything into one dataframe for train data
dataTrainAll = cbind(dataTrainChar, dataTrainNum)
#dataTrainAll$SalePrice = dataTrain$SalePrice
# corrects NAs for train data
dataTrainAll[] <- lapply(dataTrainAll, function(x) {
ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})
# combines everything into one dataframe
dataTestAll = cbind(dataTestChar, dataTestNum)
# changes NA to mean
dataTestAll <- dataTestAll %>%
mutate(across(everything(), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))
# mutate some of the data based on histogram shapes
# left/right skewed data
#dataTrainAll$TotalBsmtSF = log(dataTrain$TotalBsmtSF) # causes infinite values
#dataTestAll$TotalBsmtSF = log(dataTest$TotalBsmtSF)
dataTrainAll$X1stFlrSF = log(dataTrain$X1stFlrSF)
dataTestAll$X1stFlrSF = log(dataTest$X1stFlrSF)
dataTrainAll$GrLivArea = log(dataTrain$GrLivArea)
dataTestAll$GrLivArea = log(dataTest$GrLivArea)
highcorTrain = dataTrainAll[, c(7,17,19,20,29,33,42,44,45,50,51,54,57,61,64,65,75)]
highcorTrain = dataTrainAll[, c(7,17,19,20,29,33,42,44,45,50,51,54,57,61,64,65)]
highcorTest = dataTestAll[, c(7,17,19,20,29,33,42,44,45,50,51,54,57,61,64,65)]
# using PCA methods
pca_model <- prcomp(highcorTrain, scale. = TRUE)
# Transform train_data using the PCA model
train_data_pca <- predict(pca_model, highcorTrain)
# Transform test_data using the same PCA model
test_data_pca <- predict(pca_model, highcorTest)
dataTrainAll$SalePrice = dataTrain$SalePrice
# testing the accuracy (need to use the train data to get the accuracy) ###
dataframe_datatrain <- as.data.frame(train_data_pca)
dataframe_datatest <- as.data.frame(test_data_pca)
startModel <- lm(SalePrice ~ ., data = dataframe_datatrain)
# Predict sale prices for the test dataset
#predictions = predict(startModel, newdata = dataTestAll)
predictions1 = predict(startModel, newdata = dataframe_datatest)
predictions = exp(predictions1)
IDnum = 1461:2919
MySubmission = data.frame(Id = IDnum, SalePrice = predictions)
write.csv(MySubmission, "predictionslinearRegression.csv", row.names=FALSE)
